1
00:00:00,000 --> 00:00:05,000
How do you remember previous parts of the conversation?
你是如何记住以前的谈话内容的？

2
00:00:05,000 --> 00:00:12,000
When you interact with these models, naturally they don't remember what you say before or any of the previous conversation,
当你与这些模型互动时，他们自然不记得你之前说过什么，也不记得之前的任何对话、

3
00:00:12,000 --> 00:00:18,000
which is an issue when you're building some applications like Chatbot and you want to have a conversation with them.
这是一个问题，当你建立一些应用程序，如聊天机器人，你想与他们进行对话。

4
00:00:18,000 --> 00:00:24,000
And so in this section, we'll cover memory, which is basically how do you remember previous parts of the conversation
因此，在这一节中，我们将涉及记忆，也就是基本上你如何记住以前的对话部分

5
00:00:24,000 --> 00:00:31,000
and feed that into the language model so that they can have this conversational flow as you're interacting with them.
并将其反馈到语言模型中，这样他们就可以在你与他们互动时有这种对话流程。

6
00:00:31,000 --> 00:00:36,000
So LangChain offers multiple sophisticated options for managing these memories.
所以LangChain为管理这些记忆提供了多种复杂的选择。

7
00:00:36,000 --> 00:00:38,000
Let's jump in and take a look.
让我们跳进去看一看。

8
00:00:38,000 --> 00:00:44,000
So let me start off by importing my OpenAI API key.
因此，让我从导入我的OpenAI API密钥开始。

9
00:00:44,000 --> 00:00:47,000
And then let me import a few tools that I'll need.
然后让我导入一些我需要的工具。

10
00:00:47,000 --> 00:00:55,000
Let's use as the motivating example for memory, using LangChain to manage a chat or a chatbot conversation.
让我们把使用LangChain来管理聊天或聊天机器人对话作为记忆的激励例子。

11
00:00:55,000 --> 00:01:02,000
So to do that, I'm going to set the LLM as a chat interface of OpenAI with temperature equals zero.
因此，为了做到这一点，我将把LLM设置为OpenAI的一个聊天界面，温度等于零。

12
00:01:02,000 --> 00:01:09,000
And I'm going to use the memory as a conversation buffer memory.
而我要用这个内存作为对话缓冲内存。

13
00:01:09,000 --> 00:01:13,000
And you'll see later what this means.
稍后你会看到这意味着什么。

14
00:01:13,000 --> 00:01:16,000
And I'm going to build a conversation chain.
而我要建立一个对话链。

15
00:01:16,000 --> 00:01:23,000
Again, later in this short course, Harrison will dive much more deeply into what exactly is a chain in LangChain.
同样，在本短课程的后面，Harrison将更深入地探讨LangChain中的链到底是什么。

16
00:01:23,000 --> 00:01:27,000
So don't worry too much about the details of the syntax for now.
所以暂时不要太担心语法的细节问题。

17
00:01:27,000 --> 00:01:29,000
But this builds an LLM.
但这建立了一个法律硕士。

18
00:01:29,000 --> 00:01:34,000
And if I start to have a conversation, conversation.predict, give the input.
而如果我开始进行对话，对话.预测，给予输入。

19
00:01:34,000 --> 00:01:37,000
Hi, my name is Andrew.
嗨，我的名字是安德鲁。

20
00:01:37,000 --> 00:01:39,000
Let's see what it says.
让我们看看它是怎么说的。

21
00:01:39,000 --> 00:01:41,000
Hello, Andrew. It's nice to meet you. Right. And so on.
你好，安德鲁。很高兴见到你。对。等等。

22
00:01:41,000 --> 00:01:47,000
And then let's say I ask it, what is one plus one?
然后我们说我问它，什么是一加一？

23
00:01:47,000 --> 00:01:51,000
One plus one is two. And then I'll ask it again.
一加一就是二。然后我再问一遍。

24
00:01:51,000 --> 00:01:53,000
You know, what's my name?
你知道，我叫什么名字？

25
00:01:53,000 --> 00:01:55,000
Your name is Andrew, as you mentioned earlier.
你的名字是安德鲁，正如你之前提到的。

26
00:01:55,000 --> 00:01:59,000
There's a lot of trace of sarcasm there. Not sure.
那里有很多讽刺的痕迹。不确定。

27
00:01:59,000 --> 00:02:06,000
And so if you want, you can change this verbose variable to true to see what LangChain is actually doing.
因此，如果你愿意，你可以把这个verbose变量改为true，看看LangChain到底在做什么。

28
00:02:06,000 --> 00:02:09,000
When you run predict, hi, my name is Andrew.
当你运行预测，嗨，我的名字是安德鲁。

29
00:02:09,000 --> 00:02:11,000
This is the prompt that LangChain is generating.
这是LangChain正在生成的提示。

30
00:02:11,000 --> 00:02:15,000
It says the following is a friendly conversation between a human and an AI.
它说以下是人类和人工智能之间的友好对话。

31
00:02:15,000 --> 00:02:17,000
The AI is talkative and so on.
人工智能很健谈，等等。

32
00:02:17,000 --> 00:02:23,000
So this is a prompt that LangChain has generated to have the system have a hopeful and friendly conversation.
所以这是LangChain产生的提示，让系统有一个充满希望和友好的对话。

33
00:02:23,000 --> 00:02:26,000
And it has to save the conversation. And here's the response.
而且必须要挽救这个对话。而这里是回应。

34
00:02:26,000 --> 00:02:36,000
And when you execute this on the second and third parts of the conversations, it keeps the prompt as follows.
而当你在对话的第二和第三部分执行时，会保持如下的提示。

35
00:02:36,000 --> 00:02:40,000
And notice that by the time I'm uttering, what is my name?
并注意到，在我说出，我的名字是什么的时候？

36
00:02:40,000 --> 00:02:43,000
This is the third turn. That's my third input.
这是第三轮。这是我的第三次输入。

37
00:02:43,000 --> 00:02:47,000
It has stored the current conversation as follows.
它已将当前的谈话内容储存如下。

38
00:02:47,000 --> 00:02:51,000
Hi, my name is Andrew. What is one plus one? And so on.
嗨，我的名字是安德鲁。什么是一加一？等等。

39
00:02:51,000 --> 00:02:57,000
And so this memory or this history of the conversation gets longer and longer.
于是这段记忆或这段对话的历史变得越来越长。

40
00:02:57,000 --> 00:03:02,000
In fact, up on top, I had used the memory variable to store the memory.
事实上，在上面，我曾用内存变量来存储内存。

41
00:03:02,000 --> 00:03:09,000
So if I were to print memory.buffer, it has stored the conversation so far.
因此，如果我打印memory.buffer，它已经存储了到目前为止的对话。

42
00:03:09,000 --> 00:03:14,000
You can also print this out, memory.loadMemoryVariables.
你也可以把这个打印出来，memory.loadMemoryVariables。

43
00:03:14,000 --> 00:03:18,000
The curly braces here is actually an empty dictionary.
这里的大括号实际上是一个空的字典。

44
00:03:18,000 --> 00:03:25,000
There's some more advanced features that you can use with a more sophisticated input, but we won't talk about them in this short course.
还有一些更高级的功能，你可以用更复杂的输入法来使用，但我们不会在这个短课程中谈论它们。

45
00:03:25,000 --> 00:03:28,000
So don't worry about why there's empty curly braces here.
所以不要担心为什么这里有空的大括号。

46
00:03:28,000 --> 00:03:33,000
But this is what LangChain has remembered in the memory of the conversation so far.
但这是LangChain在迄今为止的对话记忆中所记住的。

47
00:03:33,000 --> 00:03:38,000
It's just everything that the AI or that the human has said.
这只是人工智能或人类说过的一切。

48
00:03:38,000 --> 00:03:41,000
I encourage you to pause the video and run the code.
我鼓励你暂停该视频并运行该代码。

49
00:03:41,000 --> 00:03:49,000
So the way that LangChain is storing the conversation is with this conversation buffer memory.
因此，LangChain存储对话的方式是用这个对话缓冲存储器。

50
00:03:49,000 --> 00:03:55,000
If I were to use the conversation buffer memory to specify a couple of inputs and outputs,
如果我使用对话缓冲存储器来指定几个输入和输出、

51
00:03:55,000 --> 00:03:59,000
this is how you add new things to the memory if you wish to do so explicitly.
如果你想明确地添加新的东西到内存中，这就是你的方法。

52
00:03:59,000 --> 00:04:03,000
Memory.saveContext says, "Hi, what's up?"
Memory.saveContext说，"嗨，怎么了？"

53
00:04:03,000 --> 00:04:09,000
I know this is not the most exciting conversation, but I wanted to have a short example.
我知道这不是最激动人心的谈话，但我想有一个简短的例子。

54
00:04:09,000 --> 00:04:15,000
And with that, this is what the status of the memory is.
就这样，这就是记忆的现状。

55
00:04:15,000 --> 00:04:21,000
And once again, let me actually show the memory variables.
再一次，让我实际展示一下内存变量。

56
00:04:21,000 --> 00:04:29,000
Now, if you want to add additional data to the memory, you can keep on saving additional context.
现在，如果你想在内存中添加额外的数据，你可以继续保存额外的上下文。

57
00:04:29,000 --> 00:04:34,000
So conversation goes on, not much, just hanging, cool.
所以谈话继续进行，不多，只是挂着，很酷。

58
00:04:34,000 --> 00:04:38,000
And if you print out the memory, there's now more stuff in it.
而如果你把内存打印出来，现在里面有更多的东西。

59
00:04:38,000 --> 00:04:43,000
So when you use a large language model for a chat conversation,
因此，当你使用一个大的语言模型进行聊天对话时、

60
00:04:43,000 --> 00:04:46,000
the large language model itself is actually stateless.
大型语言模型本身实际上是无状态的。

61
00:04:46,000 --> 00:04:51,000
The language model itself does not remember the conversation you've had so far.
语言模型本身并不记得你到目前为止的对话。

62
00:04:51,000 --> 00:04:55,000
And each transaction, each call to the API endpoint is independent.
而每个交易，每个对API端点的调用都是独立的。

63
00:04:55,000 --> 00:05:02,000
And chatbots appear to have memory only because there's usually rapid code
而聊天机器人看起来有记忆，只是因为通常有快速的代码

64
00:05:02,000 --> 00:05:07,000
that provides the full conversation that's been had so far as context to the LLM.
这篇文章提供了迄今为止作为法律硕士背景的全部对话。

65
00:05:07,000 --> 00:05:14,000
And so the memory can store explicitly the terms or the utterances so far,
因此，记忆可以明确地存储到目前为止的术语或话语、

66
00:05:14,000 --> 00:05:17,000
"Hi, my name is Andrew," "Hello, Andrew, it's nice to meet you," and so on.
"你好，我叫安德鲁，""你好，安德鲁，很高兴见到你，"等等。

67
00:05:17,000 --> 00:05:22,000
And this memory storage is used as input or additional context to the LLM
而这个内存存储被用作LLM的输入或附加背景

68
00:05:22,000 --> 00:05:28,000
so that it can generate an output as if it's just having the next conversational turn,
这样它就能产生一个输出，就好像它只是在进行下一个对话回合、

69
00:05:28,000 --> 00:05:30,000
knowing what's been said before.
知道以前说过什么。

70
00:05:30,000 --> 00:05:37,000
And as the conversation becomes long, the amounts of memory needed becomes really, really long.
当对话变得很长时，所需的内存量也变得非常非常长。

71
00:05:37,000 --> 00:05:40,000
And thus, the cost of sending a lot of tokens to the LLM,
因此，向LLM发送大量代币的成本、

72
00:05:40,000 --> 00:05:44,000
which usually charges based on the number of tokens it needs to process,
它通常根据它需要处理的代币数量来收费、

73
00:05:44,000 --> 00:05:46,000
will also become more expensive.
也将变得更加昂贵。

74
00:05:46,000 --> 00:05:54,000
So LLM provides several convenient kinds of memory to store and accumulate the conversation.
所以LLM提供了几种方便的存储器来存储和积累对话。

75
00:05:54,000 --> 00:05:58,000
So far, we've been looking at the conversation buffer memory.
到目前为止，我们一直在看对话缓冲区的内存。

76
00:05:58,000 --> 00:06:00,000
Let's look at a different type of memory.
让我们看一下不同类型的记忆。

77
00:06:00,000 --> 00:06:09,000
I'm going to import the conversation buffer window memory that only keeps a window of memory.
我要导入只保留一个窗口内存的对话缓冲区。

78
00:06:09,000 --> 00:06:14,000
If I set memory to conversational buffer window memory with k=1,
如果我将内存设置为对话缓冲区窗口内存，k=1、

79
00:06:14,000 --> 00:06:20,000
the variable k=1 specifies that I want it to remember just one conversational exchange.
变量k=1表示我希望它只记住一次对话交流。

80
00:06:20,000 --> 00:06:25,000
That is, one utterance from me and one utterance from the chatbot.
也就是说，我说一句话，聊天机器人就说一句话。

81
00:06:25,000 --> 00:06:31,000
So now if I were to have it save context, "Hi, what's up," not much, just hanging.
所以现在如果我让它保存上下文，"嗨，怎么了？"不多，只是挂着。

82
00:06:31,000 --> 00:06:39,000
If I were to look at memory.load variables, it only remembers the most recent utterance.
如果我看一下memory.load的变量，它只记得最近的话语。

83
00:06:39,000 --> 00:06:41,000
Notice it's dropped. "Hi, what's up?"
注意到它被丢弃了。"嗨，怎么了？"

84
00:06:41,000 --> 00:06:45,000
It's just saying, "Human says not much, just hanging," and the AI says "Cool."
它只是说，"人类说的不多，只是挂着"，而人工智能说 "酷"。

85
00:06:45,000 --> 00:06:48,000
So that's because k was equal to 1.
所以这是因为k等于1。

86
00:06:48,000 --> 00:06:56,000
So this is a nice feature because it lets you keep track of just the most recent few conversational turns.
因此，这是一个很好的功能，因为它可以让你只跟踪最近的几个对话回合。

87
00:06:56,000 --> 00:06:59,000
In practice, you probably won't use this with k=1.
在实践中，你可能不会在k=1的情况下使用这个。

88
00:06:59,000 --> 00:07:03,000
You use this with k set to a larger number.
你在使用时，将k设置为一个较大的数字。

89
00:07:03,000 --> 00:07:10,000
But still, this prevents the memory from growing without limit as the conversation goes longer.
但是，这仍然阻止了记忆随着谈话的延长而无限制地增长。

90
00:07:10,000 --> 00:07:19,000
And so if I were to rerun the conversation that we had just now,
因此，如果我重演我们刚才的对话、

91
00:07:19,000 --> 00:07:27,000
we'll say, "Hi, my name is Andrew. What is 1+1?"
我们会说，"嗨，我的名字是安德鲁。什么是1+1？"

92
00:07:27,000 --> 00:07:32,000
And now I ask it, "What is my name?"
现在我问它："我的名字是什么？"

93
00:07:32,000 --> 00:07:37,000
Because k=1, it only remembers the last exchange versus "What is 1+1?"
因为k=1，它只记得最后一次交换与 "1+1是什么？"

94
00:07:37,000 --> 00:07:42,000
The answer is 1+1=2, and it's forgotten this early exchange, which now says,
答案是1+1=2，它忘记了这个早期的交流，现在说、

95
00:07:42,000 --> 00:07:46,000
"Sorry, don't have access to that information."
"对不起，没有机会接触到这些信息。"

96
00:07:46,000 --> 00:07:53,000
One thing I hope you will do is pause the video, change this to true in the code on the left,
我希望你能做的一件事是暂停视频，在左边的代码中把这一点改为真、

97
00:07:53,000 --> 00:07:57,000
and rerun this conversation with verbose=true,
并以verbose=true重新运行这个对话、

98
00:07:57,000 --> 00:08:00,000
and then you will see the prompts actually used to generate this,
然后你会看到实际用于生成这个的提示、

99
00:08:00,000 --> 00:08:07,000
and hopefully you see that the memory, when you're calling the LLM on "What is my name?"
并希望你看到，当你在 "我叫什么名字？"上打电话给法律硕士时，记忆力。

100
00:08:07,000 --> 00:08:11,000
that the memory has dropped this exchange where it learned "What is my name?"
记忆中已经放弃了这种交流，在那里它学会了 "我的名字是什么？"

101
00:08:11,000 --> 00:08:17,000
which is why it now says it doesn't know "What is my name?"
这就是为什么它现在说它不知道 "我的名字是什么？"

102
00:08:17,000 --> 00:08:23,000
With the conversational token buffer memory,
有了对话令牌缓冲存储器、

103
00:08:23,000 --> 00:08:28,000
the memory will limit the number of tokens saved.
存储器将限制保存的代币数量。

104
00:08:28,000 --> 00:08:32,000
And because a lot of LLM pricing is based on tokens,
而且因为很多LLM的定价都是基于代币的、

105
00:08:32,000 --> 00:08:39,000
this maps more directly to the cost of the LLM calls.
这更直接地反映了LLM呼叫的成本。

106
00:08:39,000 --> 00:08:44,000
So if I were to say the max token limit is equal to 50,
因此，如果我说最大的代币限额等于50、

107
00:08:44,000 --> 00:08:47,000
and actually let me inject a few comments.
实际上让我注入一些评论。

108
00:08:47,000 --> 00:08:51,000
So let's say the conversation is, "AI is what? Amazing."
所以我们说对话是："AI是什么？很神奇。"

109
00:08:51,000 --> 00:08:54,000
Back propagation is "What? Beautiful." Chatbot is "What? Charming."
背面传播是 "什么？"美丽。聊天机器人是 "什么？迷人。"

110
00:08:54,000 --> 00:08:58,000
I use ABC as the first letter of all of these conversational terms.
我把ABC作为所有这些对话术语的第一个字母。

111
00:08:58,000 --> 00:09:02,000
We can keep track of what was said when.
我们可以记下什么时候说过什么话。

112
00:09:02,000 --> 00:09:05,000
If I run this with a high token limit,
如果我用高的代币限额来运行这个、

113
00:09:05,000 --> 00:09:08,000
it has almost the whole conversation.
它几乎有整个对话。

114
00:09:08,000 --> 00:09:12,000
If I increase the token limit to 100,
如果我把代币的上限提高到100、

115
00:09:12,000 --> 00:09:16,000
it now has the whole conversation starting with "AI is what?"
现在整个对话都以 "人工智能是什么？"开始。

116
00:09:16,000 --> 00:09:19,000
If I decrease it,
如果我减少它、

117
00:09:19,000 --> 00:09:24,000
then it chops off the earlier parts of this conversation
然后它把这个对话的早期部分砍掉了

118
00:09:24,000 --> 00:09:28,000
to retain the number of tokens corresponding to the most recent exchanges,
以保留最近一次交易所对应的代币数量、

119
00:09:28,000 --> 00:09:32,000
but subject to not exceeding the token limit.
但以不超过代币限额为前提。

120
00:09:32,000 --> 00:09:35,000
In case you're wondering why we needed to specify an LLM,
如果你想知道为什么我们需要指定一个法律硕士、

121
00:09:35,000 --> 00:09:39,000
it's because different LLMs use different ways of counting tokens.
这是因为不同的LLM使用不同的方式来计算tokens。

122
00:09:39,000 --> 00:09:42,000
So this tells it to use the way of counting tokens
因此，这告诉它要使用计数令牌的方式

123
00:09:42,000 --> 00:09:46,000
that the chat OpenAI LLM uses.
聊天的OpenAI LLM使用的是 "A"。

124
00:09:46,000 --> 00:09:49,000
I encourage you to pause the video and run the code,
我鼓励你暂停该视频并运行该代码、

125
00:09:49,000 --> 00:09:54,000
and also try modifying the prompt to see if you can get a different output.
并尝试修改提示，看看是否能得到不同的输出。

126
00:09:54,000 --> 00:09:58,000
Finally, there's one last type of memory I want to illustrate here,
最后，我想在这里说明的是最后一种类型的记忆、

127
00:09:58,000 --> 00:10:04,000
which is the conversation summary buffer memory.
这是对话摘要缓冲区的内存。

128
00:10:04,000 --> 00:10:08,000
And the idea is, instead of limiting the memory
而这个想法是，与其限制内存

129
00:10:08,000 --> 00:10:12,000
to a fixed number of tokens based on the most recent utterances,
语词的固定数量，以最近的语词为基础、

130
00:10:12,000 --> 00:10:15,000
or a fixed number of conversational exchanges,
或固定数量的对话交流、

131
00:10:15,000 --> 00:10:20,000
let's use an LLM to write a summary of the conversation so far,
让我们用一个法律硕士来写一个到目前为止的谈话摘要、

132
00:10:20,000 --> 00:10:24,000
and let that be the memory.
并让这成为记忆。

133
00:10:24,000 --> 00:10:27,000
So here's an example where I'm going to create a long string
因此，这里有一个例子，我将创建一个长字符串

134
00:10:27,000 --> 00:10:29,000
with someone's schedule.
与某人的时间表。

135
00:10:29,000 --> 00:10:31,000
"This meeting at 8am with your product team,
"早上8点和你的产品团队开这个会、

136
00:10:31,000 --> 00:10:34,000
you need your PowerPoint presentation," and so on and so on.
你需要你的PowerPoint演示文稿，"等等，等等。

137
00:10:34,000 --> 00:10:38,000
So this is a long string saying what's your schedule.
所以这是一长串说你的时间表是什么。

138
00:10:38,000 --> 00:10:42,000
Maybe ending with a noon lunch at the Italian restaurant with a customer,
也许以中午在意大利餐厅与顾客共进午餐结束、

139
00:10:42,000 --> 00:10:46,000
bring your laptop, show the latest LLM demo.
带上你的笔记本电脑，展示最新的LLM演示。

140
00:10:46,000 --> 00:10:53,000
And so let me use a conversation summary buffer memory
因此，让我用一个对话摘要缓冲记忆

141
00:10:53,000 --> 00:10:56,000
with a max token limit of 400 in this case,
在这种情况下，最大令牌限制为400、

142
00:10:56,000 --> 00:10:58,000
pretty high token limit,
相当高的代币限额、

143
00:10:58,000 --> 00:11:04,000
and I'm going to insert in a few conversational terms,
而我要在其中插入一些对话性的术语、

144
00:11:04,000 --> 00:11:06,000
in which we start with "Hello," "What's up,"
其中，我们以 "你好"、"你好 "开始。

145
00:11:06,000 --> 00:11:10,000
"No one's just hanging," "Cool,"
"没有人只是挂着。""很酷。"

146
00:11:10,000 --> 00:11:13,000
and then "What is on the schedule today?"
然后是 "今天有什么安排？"

147
00:11:13,000 --> 00:11:17,000
and the response is, you know, "That long schedule."
而回应是，你知道，"那个漫长的时间表"。

148
00:11:17,000 --> 00:11:22,000
So this memory now has quite a lot of text in it.
因此，这段记忆现在有相当多的文字在里面。

149
00:11:22,000 --> 00:11:26,000
In fact, let's take a look at the memory variables.
事实上，让我们看一下内存变量。

150
00:11:26,000 --> 00:11:31,000
It contains that entire piece of text
它包含了那一整片的文字

151
00:11:31,000 --> 00:11:37,000
because 400 tokens was sufficient to store all this text.
因为400个令牌足以存储所有这些文本。

152
00:11:37,000 --> 00:11:43,000
But now, if I were to reduce the max token limit, say to 100 tokens,
但现在，如果我减少最大的代币限制，比如说减少到100个代币、

153
00:11:43,000 --> 00:11:46,000
remember this stores the entire conversational history.
请记住，这储存了整个对话历史。

154
00:11:46,000 --> 00:11:51,000
If I reduce the number of tokens to 100,
如果我把代币的数量减少到100个、

155
00:11:51,000 --> 00:11:57,000
then the conversation summary buffer memory has actually used an LLM,
那么对话摘要缓冲区内存实际上已经使用了一个LLM、

156
00:11:57,000 --> 00:11:59,000
the OpenAI endpoint in this case,
在这种情况下的OpenAI端点、

157
00:11:59,000 --> 00:12:01,000
because that's what we have set the LLM to,
因为这就是我们为LLM设定的目标、

158
00:12:01,000 --> 00:12:05,000
to actually generate a summary of the conversation so far.
来实际生成一个迄今为止的对话摘要。

159
00:12:05,000 --> 00:12:09,000
So the summary is, "Human AI engage in small talk before a certain day's schedule,"
因此，总结起来就是："人类人工智能在某一天的日程安排之前进行小范围的交谈"。

160
00:12:09,000 --> 00:12:13,000
"AI informs human in a morning meeting," blah, blah, blah,
"人工智能在晨会上通知人类，"等等，等等，等等、

161
00:12:13,000 --> 00:12:18,000
"Lunch meeting with customer interested in AI, latest AI developments."
"与对人工智能感兴趣的客户进行午餐会议，最新的人工智能发展。"

162
00:12:18,000 --> 00:12:28,000
And so, if we were to have a conversation using this LLM,
因此，如果我们要用这个法学硕士来进行对话、

163
00:12:28,000 --> 00:12:33,000
then create a conversation chain, same as before,
然后创建一个对话链，和以前一样、

164
00:12:33,000 --> 00:12:38,000
and let's say that we were to ask input,
假设我们要问投入、

165
00:12:38,000 --> 00:12:41,000
"What would be a good demo to show?"
"有什么好的演示可以展示？"

166
00:12:41,000 --> 00:12:45,000
I said verbose equals true, so here's the prompt.
我说过verbose等于true，所以这里有提示。

167
00:12:45,000 --> 00:12:53,000
The LLM thinks the current conversation has had this discussion so far
法学硕士认为目前的谈话到目前为止有这样的讨论

168
00:12:53,000 --> 00:12:56,000
because that's the summary of the conversation.
因为这就是谈话的摘要。

169
00:12:56,000 --> 00:13:03,000
And just one note, if you're familiar with the OpenAI chat API endpoint,
还有一点，如果你熟悉OpenAI的聊天API端点、

170
00:13:03,000 --> 00:13:06,000
there is a specific system message.
有一个特定的系统信息。

171
00:13:06,000 --> 00:13:11,000
In this example, this is not using the official OpenAI system message,
在这个例子中，这不是使用OpenAI的官方系统信息、

172
00:13:11,000 --> 00:13:14,000
it's just including it as part of the prompt here,
它只是把它作为这里的提示的一部分、

173
00:13:14,000 --> 00:13:16,000
but it nonetheless works pretty well.
但它还是很好用。

174
00:13:16,000 --> 00:13:19,000
And given this prompt, the LLM outputs,
而鉴于这种提示，法律硕士的输出、

175
00:13:19,000 --> 00:13:21,000
"Basic conversation in AI developments,"
"人工智能发展中的基本对话"。

176
00:13:21,000 --> 00:13:24,000
"suggests showcasing our latest NLP capabilities."
"建议展示我们最新的NLP能力"。

177
00:13:24,000 --> 00:13:28,000
Okay, that's cool.
好的，这很好。

178
00:13:28,000 --> 00:13:31,000
Well, it's making some suggestions to the cool demos
好吧，它对酷炫的演示提出了一些建议

179
00:13:31,000 --> 00:13:35,000
and makes you think, if I was meeting a customer, I would say,
并让你想到，如果我是在见一个顾客，我会说、

180
00:13:35,000 --> 00:13:39,000
"Boy, if only there were open source framework available
"孩子，如果有开放源码的框架就好了

181
00:13:39,000 --> 00:13:43,000
to help me build cool NLP applications using LLMs."
以帮助我使用LLM建立很酷的NLP应用。"

182
00:13:43,000 --> 00:13:48,000
Good things are launching.
好东西正在启动。

183
00:13:48,000 --> 00:13:50,000
And the interesting thing is,
而有趣的是、

184
00:13:50,000 --> 00:13:58,000
if you now look at what has happened to the memory,
如果你现在看一下记忆发生了什么、

185
00:13:58,000 --> 00:14:04,000
so notice that here it has incorporated the most recent AI system output,
所以请注意，这里它已经纳入了最新的人工智能系统输出、

186
00:14:04,000 --> 00:14:08,000
whereas my utterance, asking it, "Won't be a good demo to show,"
而我的发言，问它："不会是一个很好的演示节目吧。"

187
00:14:08,000 --> 00:14:11,000
has been incorporated into the system message,
已被纳入系统信息、

188
00:14:11,000 --> 00:14:14,000
the overall summary of the conversation so far.
到目前为止，对话的总体总结。

189
00:14:14,000 --> 00:14:17,000
With the conversation summary buffer memory,
有了对话摘要缓冲存储器、

190
00:14:17,000 --> 00:14:23,000
what it tries to do is keep the explicit storage of the messages
它试图做的是保持信息的明确存储

191
00:14:23,000 --> 00:14:27,000
up to the number of tokens we have specified as a limit.
到我们指定的代币数量为限。

192
00:14:27,000 --> 00:14:30,000
So, you know, this part, the explicit storage,
所以，你知道，这部分，明确的存储、

193
00:14:30,000 --> 00:14:34,000
we try to cap at 100 tokens because that's what we asked for.
我们试图将上限定为100个代币，因为这是我们要求的。

194
00:14:34,000 --> 00:14:38,000
And then anything beyond that, it will use the LLM to generate a summary,
然后任何超出这个范围的事情，它都会使用LLM来生成一个摘要、

195
00:14:38,000 --> 00:14:41,000
which is what is seen up here.
这就是在这里看到的情况。

196
00:14:41,000 --> 00:14:43,000
And even though I've illustrated these different memories
尽管我已经说明了这些不同的记忆

197
00:14:43,000 --> 00:14:46,000
using a chat as a running example,
用一个聊天记录作为一个运行的例子、

198
00:14:46,000 --> 00:14:49,000
these memories are useful for other applications too,
这些记忆对其他应用也很有用、

199
00:14:49,000 --> 00:14:52,000
where you might keep on getting new snippets of text
在这里你可能会不断得到新的文本片段

200
00:14:52,000 --> 00:14:54,000
or keep on getting new information,
或不断获得新的信息、

201
00:14:54,000 --> 00:14:58,000
such as if your system repeatedly goes online to search for facts,
例如，如果你的系统反复上网搜索事实、

202
00:14:58,000 --> 00:15:03,000
but you want to keep the total memory used to store this growing list of facts
但你想保持用于存储这个不断增长的事实列表的总内存

203
00:15:03,000 --> 00:15:07,000
as, you know, capped and not growing arbitrarily long.
因为，你知道，有上限，不会任意增长。

204
00:15:07,000 --> 00:15:11,000
I encourage you to pause the video and run the code.
我鼓励你暂停该视频并运行该代码。

205
00:15:11,000 --> 00:15:14,000
In this video, you saw a few types of memory,
在这个视频中，你看到了几种类型的内存、

206
00:15:14,000 --> 00:15:19,000
including buffer memories that limits based on number of conversation exchanges
包括基于对话交流数量限制的缓冲存储器

207
00:15:19,000 --> 00:15:26,000
or tokens, or a memory that can summarize tokens above a certain limit.
或代币，或一个能总结出超过一定限度的代币的存储器。

208
00:15:26,000 --> 00:15:29,000
LangChain actually supports additional memory types as well.
LangChain实际上也支持额外的内存类型。

209
00:15:29,000 --> 00:15:32,000
One of the most powerful is vector data memory.
其中最强大的是矢量数据存储器。

210
00:15:32,000 --> 00:15:36,000
If you're familiar with word embeddings and text embeddings,
如果你熟悉单词嵌入和文本嵌入、

211
00:15:36,000 --> 00:15:38,000
the vector database actually stores such embeddings.
矢量数据库实际上存储了这种嵌入。

212
00:15:38,000 --> 00:15:41,000
If you don't know what that means, don't worry about it.
如果你不知道这意味着什么，就不要担心了。

213
00:15:41,000 --> 00:15:43,000
Harrison will explain it later.
哈里森以后会解释。

214
00:15:43,000 --> 00:15:47,000
And it can then retrieve the most relevant blocks of text
然后，它可以检索到最相关的文本块

215
00:15:47,000 --> 00:15:51,000
using this type of vector database for its memory.
使用这种类型的矢量数据库作为其内存。

216
00:15:51,000 --> 00:15:54,000
And LangChain also supports entity memories,
而LangChain也支持实体记忆、

217
00:15:54,000 --> 00:15:59,000
which is applicable when you want it to remember details about specific people,
这适用于你想让它记住特定人的细节的时候、

218
00:15:59,000 --> 00:16:04,000
specific other entities, such as if you talk about a specific friend,
具体的其他实体，比如说如果你谈论一个具体的朋友、

219
00:16:04,000 --> 00:16:08,000
you can have LangChain remember facts about that friend,
你可以让LangChain记住关于那个朋友的事实、

220
00:16:08,000 --> 00:16:12,000
which would be an entity in an explicit way.
这将是一个实体的明确方式。

221
00:16:12,000 --> 00:16:14,000
When you're implementing applications using LangChain,
当你使用LangChain实现应用程序时、

222
00:16:14,000 --> 00:16:17,000
you can also use multiple types of memories,
你也可以使用多种类型的记忆、

223
00:16:17,000 --> 00:16:22,000
such as using one of the types of conversation memory that you saw in this video,
例如使用你在这段视频中看到的对话记忆类型之一、

224
00:16:22,000 --> 00:16:26,000
plus additionally, entity memory to recall individuals.
另外，实体记忆来回忆个人。

225
00:16:26,000 --> 00:16:30,000
So this way, you can remember maybe a summary of the conversation,
所以这样一来，你就可以记住也许是谈话的摘要、

226
00:16:30,000 --> 00:16:35,000
plus an explicit way of storing important facts about important people in the conversation.
再加上一种明确的方式来存储谈话中重要人物的重要事实。

227
00:16:35,000 --> 00:16:38,000
And of course, in addition to using these memory types,
当然，除了使用这些内存类型之外、

228
00:16:38,000 --> 00:16:42,000
it's also not uncommon for developers to store the entire conversation
开发者将整个对话内容存储起来也是很常见的。

229
00:16:42,000 --> 00:16:46,000
in the conventional database, some sort of key value store or SQL database.
在传统数据库中，某种键值存储或SQL数据库。

230
00:16:46,000 --> 00:16:49,000
So you could refer back to the whole conversation for auditing
因此，你可以参考整个对话来进行审计

231
00:16:49,000 --> 00:16:52,000
or for improving the system further.
或用于进一步改进该系统。

232
00:16:52,000 --> 00:16:54,000
And so that's memory types.
所以这就是记忆类型。

233
00:16:54,000 --> 00:16:57,000
I hope you find this useful building your own applications.
我希望你在建立你自己的应用程序时发现这很有用。

234
00:16:57,000 --> 00:17:03,000
And now let's go on to the next video to learn about the key building block of LangChain,
现在让我们继续看下一个视频，了解LangChain的关键构建块、

235
00:17:03,000 --> 00:17:05,000
namely the chain.
即链条。

